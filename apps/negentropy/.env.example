# =============================================================================
# Negentropy Environment Configuration
# =============================================================================
# Copy this file to .env and modify as needed.
# For environment-specific overrides, create .env.{environment} files.
#
# File Loading Order (later overrides earlier):
#   1. .env                    (base defaults)
#   2. .env.local              (local overrides, gitignored)
#   3. .env.{environment}      (environment-specific)
#   4. .env.{environment}.local (local env overrides, gitignored)
#
# =============================================================================

# -----------------------------------------------------------------------------
# Environment Selection
# -----------------------------------------------------------------------------
# Options: development | testing | staging | production
# Default: development
NE_ENV=development

# -----------------------------------------------------------------------------
# LLM Configuration (Prefix: NE_LLM_)
# -----------------------------------------------------------------------------
# Vendor: openai | anthropic | zai | vertex_ai | deepseek | ollama
NE_LLM_VENDOR=zai
NE_LLM_MODEL_NAME=glm-4.7

# Generation parameters
NE_LLM_TEMPERATURE=0.7

# Thinking/Reasoning Mode (for Claude 3.7+ / GLM-4.7 / OpenAI o1)
# Set to True to enable extended reasoning capabilities
NE_LLM_THINKING_MODE=False
NE_LLM_THINKING_BUDGET=2048        # Token budget for thinking
NE_LLM_REASONING_EFFORT=medium     # low | medium | high (for OpenAI o1)
NE_LLM_PRESERVE_THINKING=False     # Enable preserved thinking for multi-turn coherence (GLM)

# -----------------------------------------------------------------------------
# ZAI (Zhipu AI) API Configuration
# -----------------------------------------------------------------------------
# LiteLLM native support for Zhipu AI / GLM models
# Reference: https://docs.litellm.ai/docs/providers/zai
# Using BigModel Coding endpoint (different billing pool from z.ai)
ZAI_API_KEY=your-api-key-here
ZAI_API_BASE=https://open.bigmodel.cn/api/coding/paas/v4

# -----------------------------------------------------------------------------
# Logging Configuration (Prefix: NE_LOG_)
# -----------------------------------------------------------------------------
# Level: DEBUG | INFO | WARNING | ERROR | CRITICAL
NE_LOG_LEVEL=INFO

# Format: console (colored, human-readable) | json (structured, machine-readable)
NE_LOG_FORMAT=console

# Sinks: comma-separated list of: stdio | file | gcloud
NE_LOG_SINKS=stdio

# File sink settings
NE_LOG_FILE_PATH=logs/negentropy.log

# GCloud sink settings
NE_LOG_GCLOUD_LOG_NAME=negentropy

# -----------------------------------------------------------------------------
# Database Configuration (Prefix: NE_DB_)
# -----------------------------------------------------------------------------
NE_DB_URL=postgresql+asyncpg://aigc:@localhost:5432/negentropy

# Connection pool settings
NE_DB_POOL_SIZE=5
NE_DB_MAX_OVERFLOW=10
NE_DB_POOL_RECYCLE=3600

# SQL echo (set True for debugging)
NE_DB_ECHO=False

# -----------------------------------------------------------------------------
# Observability Configuration (Prefix: NE_OBSERVABILITY_)
# -----------------------------------------------------------------------------
# Langfuse Integration (Tracing & Metrics)
# Host defaults to https://cloud.langfuse.com if not specified
NE_OBSERVABILITY_LANGFUSE_ENABLED=True
NE_OBSERVABILITY_LANGFUSE_HOST=https://cloud.langfuse.com
NE_OBSERVABILITY_LANGFUSE_PUBLIC_KEY=pk-lf-your-public-key
NE_OBSERVABILITY_LANGFUSE_SECRET_KEY=sk-lf-your-secret-key

# -----------------------------------------------------------------------------
# ADK Services Configuration (Prefix: NE_SVC_)
# -----------------------------------------------------------------------------
# Credential Backend: inmemory | postgres | session
NE_SVC_CREDENTIAL_BACKEND=inmemory

# Session Backend: inmemory | vertexai | database | postgres
NE_SVC_SESSION_BACKEND=inmemory

# Memory Backend: inmemory | vertexai | postgres
NE_SVC_MEMORY_BACKEND=inmemory

# Artifact Backend: inmemory | gcs
NE_SVC_ARTIFACT_BACKEND=inmemory

# GCS Configuration (required if artifact_backend=gcs)
NE_SVC_GCS_BUCKET_NAME=negentropy

# VertexAI Configuration (required for vertexai backends)
# NE_SVC_VERTEX_PROJECT_ID=your-project-id
# NE_SVC_VERTEX_LOCATION=us-central1
# NE_SVC_VERTEX_AGENT_ENGINE_ID=your-agent-engine-id

# =============================================================================
# Environment-Specific Recommendations
# =============================================================================
#
# DEVELOPMENT:
#   NE_ENV=development
#   NE_LOG_LEVEL=DEBUG
#   NE_LOG_FORMAT=console
#   NE_DB_ECHO=True
#   NE_SVC_*_BACKEND=inmemory
#
# TESTING:
#   NE_ENV=testing
#   NE_LOG_LEVEL=WARNING
#   NE_LOG_FORMAT=json
#   NE_DB_URL=postgresql+asyncpg://...negentropy_test
#   NE_SVC_*_BACKEND=inmemory
#
# STAGING:
#   NE_ENV=staging
#   NE_LOG_LEVEL=INFO
#   NE_LOG_FORMAT=json
#   NE_LOG_SINKS=stdio,gcloud
#   NE_SVC_*_BACKEND=postgres or database
#
# PRODUCTION:
#   NE_ENV=production
#   NE_LOG_LEVEL=INFO
#   NE_LOG_FORMAT=json
#   NE_LOG_SINKS=stdio,gcloud
#   NE_DB_POOL_SIZE=20
#   NE_DB_MAX_OVERFLOW=30
#   NE_SVC_*_BACKEND=postgres or database
#
# =============================================================================
