"""
åˆ†å—ç®—æ³•å•å…ƒæµ‹è¯•

æµ‹è¯• chunk_text å‡½æ•°çš„è¾¹ç•Œæ¡ä»¶å’Œç‰¹æ®Šåœºæ™¯ã€‚

æ‰©å±•æµ‹è¯•:
- Fixed åˆ†å—: å›ºå®šå¤§å°åˆ†å—
- Recursive åˆ†å—: é€’å½’åˆ†å—ï¼ˆæ®µè½ > å¥å­ > è¯ï¼‰
- Semantic åˆ†å—: è¯­ä¹‰åˆ†å—ï¼ˆåŸºäºå¥å­ç›¸ä¼¼åº¦ï¼‰
- ChunkingStrategy: ç­–ç•¥æšä¸¾å’Œé…ç½®éªŒè¯

å‚è€ƒæ–‡çŒ®:
[1] G. Kamalloo and A. K. G., "Semantic Chunking for RAG Applications," 2024.
[2] LlamaIndex, "Semantic Chunking," GitHub, 2024.
"""

from __future__ import annotations

import pytest
from pydantic import ValidationError

from negentropy.knowledge.chunking import (
    _cosine_similarity,
    _fixed_chunk,
    _recursive_chunk,
    _split_into_sentences,
    chunk_text,
    semantic_chunk_async,
)
from negentropy.knowledge.types import ChunkingConfig, ChunkingStrategy


class TestChunkingBasic:
    """åŸºç¡€åˆ†å—æµ‹è¯•"""

    def test_empty_text_returns_empty_list(self) -> None:
        """ç©ºæ–‡æœ¬åº”è¿”å›ç©ºåˆ—è¡¨"""
        result = chunk_text("", ChunkingConfig())
        assert result == []

    def test_whitespace_only_returns_empty_list(self) -> None:
        """çº¯ç©ºç™½æ–‡æœ¬åº”è¿”å›ç©ºåˆ—è¡¨"""
        result = chunk_text("   \n\t  ", ChunkingConfig())
        assert result == []

    def test_simple_text_chunks_correctly(self) -> None:
        """ç®€å•æ–‡æœ¬åº”æ­£ç¡®åˆ†å—"""
        text = "hello world"
        result = chunk_text(text, ChunkingConfig(chunk_size=5, overlap=0))
        assert result == ["hello", "world"]

    def test_chunk_size_larger_than_text(self) -> None:
        """åˆ†å—å¤§å°å¤§äºæ–‡æœ¬é•¿åº¦æ—¶è¿”å›æ•´ä¸ªæ–‡æœ¬"""
        text = "short"
        result = chunk_text(text, ChunkingConfig(chunk_size=100, overlap=0))
        assert result == ["short"]


class TestChunkingOverlap:
    """é‡å åˆ†å—æµ‹è¯•"""

    def test_overlap_creates_overlapping_chunks(self) -> None:
        """é‡å åˆ†å—åº”åˆ›å»ºæœ‰é‡å çš„å—"""
        text = "a" * 20
        result = chunk_text(text, ChunkingConfig(chunk_size=10, overlap=2))
        assert len(result) == 2
        # ç¬¬äºŒå—åº”åŒ…å«ç¬¬ä¸€å—çš„æœ€å 2 ä¸ªå­—ç¬¦
        assert result[1][:2] == "aa"

    def test_overlap_equal_to_chunk_size_raises_validation_error(self) -> None:
        """é‡å ç­‰äºåˆ†å—å¤§å°æ—¶åº”æŠ›å‡ºéªŒè¯å¼‚å¸¸"""
        with pytest.raises(ValidationError, match="overlap"):
            ChunkingConfig(chunk_size=10, overlap=10)


class TestChunkingNewlines:
    """æ¢è¡Œç¬¦å¤„ç†æµ‹è¯•"""

    def test_preserve_newlines_keeps_structure(self) -> None:
        """ä¿ç•™æ¢è¡Œç¬¦æ¨¡å¼åº”ä¿æŒæ–‡æœ¬ç»“æ„"""
        text = "line1\nline2\nline3"
        result = chunk_text(text, ChunkingConfig(chunk_size=10, overlap=0, preserve_newlines=True))
        assert "\n" in result[0]

    def test_remove_newlines_flattens_text(self) -> None:
        """ç§»é™¤æ¢è¡Œç¬¦æ¨¡å¼åº”å±•å¹³æ–‡æœ¬"""
        text = "line1\nline2\nline3"
        result = chunk_text(text, ChunkingConfig(chunk_size=10, overlap=0, preserve_newlines=False))
        assert "\n" not in result[0]
        assert "line1 line2" in result[0]


class TestChunkingEdgeCases:
    """è¾¹ç•Œæ¡ä»¶æµ‹è¯•"""

    def test_very_small_chunk_size(self) -> None:
        """æå°çš„åˆ†å—å¤§å°åº”æ­£å¸¸å·¥ä½œ"""
        text = "abcdef"
        result = chunk_text(text, ChunkingConfig(chunk_size=1, overlap=0))
        assert len(result) == 6
        assert result == ["a", "b", "c", "d", "e", "f"]

    def test_zero_overlap_is_accepted(self) -> None:
        """é›¶é‡å åº”è¢«æ¥å—"""
        text = "a" * 20
        result = chunk_text(text, ChunkingConfig(chunk_size=10, overlap=0))
        assert len(result) == 2
        assert result[0] != result[1]

    def test_negative_overlap_raises_validation_error(self) -> None:
        """è´Ÿé‡å åº”æŠ›å‡ºéªŒè¯å¼‚å¸¸"""
        with pytest.raises(ValidationError, match="overlap must be non-negative"):
            ChunkingConfig(chunk_size=10, overlap=-1)

    def test_text_with_special_characters(self) -> None:
        """ç‰¹æ®Šå­—ç¬¦åº”è¢«æ­£ç¡®å¤„ç†"""
        text = "Hello, ä¸–ç•Œ! ğŸš€"
        result = chunk_text(text, ChunkingConfig(chunk_size=100, overlap=0))
        assert len(result) == 1
        assert "ä¸–ç•Œ" in result[0]
        assert "ğŸš€" in result[0]

    def test_text_with_leading_trailing_whitespace(self) -> None:
        """é¦–å°¾ç©ºç™½åº”è¢«å»é™¤"""
        text = "   \n  content  \n   "
        result = chunk_text(text, ChunkingConfig(chunk_size=100, overlap=0))
        assert len(result) == 1
        assert result[0] == "content"

    def test_very_long_single_line(self) -> None:
        """è¶…é•¿å•è¡Œæ–‡æœ¬åº”æ­£ç¡®åˆ†å—"""
        text = "word " * 1000  # çº¦ 5000 å­—ç¬¦
        result = chunk_text(text, ChunkingConfig(chunk_size=500, overlap=50))
        assert len(result) > 1
        for chunk in result:
            assert len(chunk) <= 500

    def test_empty_chunks_are_filtered(self) -> None:
        """ç©ºå—åº”è¢«è¿‡æ»¤"""
        text = "a\n\n\nb"  # å¤šä¸ªæ¢è¡Œç¬¦å¯èƒ½äº§ç”Ÿç©ºå—
        result = chunk_text(text, ChunkingConfig(chunk_size=10, overlap=0, preserve_newlines=True))
        # ä¸åº”æœ‰ç©ºå­—ç¬¦ä¸²
        assert all(chunk for chunk in result)


class TestChunkingConfigValidation:
    """é…ç½®éªŒè¯æµ‹è¯•"""

    def test_chunk_size_zero_raises_validation_error(self) -> None:
        """é›¶åˆ†å—å¤§å°åº”æŠ›å‡ºéªŒè¯å¼‚å¸¸"""
        text = "abc"
        with pytest.raises(ValidationError, match="chunk_size must be at least"):
            ChunkingConfig(chunk_size=0, overlap=0)

    def test_negative_chunk_size_raises_validation_error(self) -> None:
        """è´Ÿåˆ†å—å¤§å°åº”æŠ›å‡ºéªŒè¯å¼‚å¸¸"""
        text = "abc"
        with pytest.raises(ValidationError, match="chunk_size must be at least"):
            ChunkingConfig(chunk_size=-1, overlap=0)


class TestChunkingDeterminism:
    """ç¡®å®šæ€§æµ‹è¯•"""

    def test_same_input_produces_same_output(self) -> None:
        """ç›¸åŒè¾“å…¥åº”äº§ç”Ÿç›¸åŒè¾“å‡º"""
        text = "a" * 100
        config = ChunkingConfig(chunk_size=20, overlap=5)

        result1 = chunk_text(text, config)
        result2 = chunk_text(text, config)

        assert result1 == result2


# ================================
# Sentence Splitting Tests
# ================================


class TestSentenceSplitting:
    """æµ‹è¯•å¥å­åˆ†å‰²åŠŸèƒ½"""

    def test_split_chinese_sentences(self) -> None:
        """æµ‹è¯•ä¸­æ–‡å¥å­åˆ†å‰²"""
        text = "è¿™æ˜¯ç¬¬ä¸€å¥ã€‚è¿™æ˜¯ç¬¬äºŒå¥ï¼è¿™æ˜¯ç¬¬ä¸‰å¥ï¼Ÿ"
        sentences = _split_into_sentences(text)
        assert len(sentences) == 3
        assert sentences[0] == "è¿™æ˜¯ç¬¬ä¸€å¥"
        assert sentences[1] == "è¿™æ˜¯ç¬¬äºŒå¥"
        assert sentences[2] == "è¿™æ˜¯ç¬¬ä¸‰å¥"

    def test_split_english_sentences(self) -> None:
        """æµ‹è¯•è‹±æ–‡å¥å­åˆ†å‰²"""
        text = "First sentence. Second sentence! Third sentence?"
        sentences = _split_into_sentences(text)
        assert len(sentences) == 3

    def test_split_mixed_sentences(self) -> None:
        """æµ‹è¯•ä¸­è‹±æ–‡æ··åˆå¥å­åˆ†å‰²"""
        text = "ä¸­æ–‡å¥å­ã€‚English sentence! æ··åˆ Mixed å¥å­ã€‚"
        sentences = _split_into_sentences(text)
        assert len(sentences) >= 2

    def test_split_empty_text(self) -> None:
        """æµ‹è¯•ç©ºæ–‡æœ¬åˆ†å‰²"""
        sentences = _split_into_sentences("")
        assert sentences == []

    def test_split_text_without_delimiters(self) -> None:
        """æµ‹è¯•æ²¡æœ‰åˆ†éš”ç¬¦çš„æ–‡æœ¬"""
        text = "è¿™æ˜¯æ²¡æœ‰åˆ†éš”ç¬¦çš„æ–‡æœ¬åªæ˜¯ä¸€å¥è¯"
        sentences = _split_into_sentences(text)
        assert len(sentences) == 1


# ================================
# Recursive Chunking Tests
# ================================


class TestRecursiveChunking:
    """æµ‹è¯•é€’å½’åˆ†å—"""

    @pytest.fixture
    def sample_text(self) -> str:
        """ç¤ºä¾‹æ–‡æœ¬"""
        return """
        ç¬¬ä¸€æ®µçš„ç¬¬ä¸€å¥è¯ã€‚ç¬¬ä¸€æ®µçš„ç¬¬äºŒå¥è¯ã€‚

        ç¬¬äºŒæ®µçš„ç¬¬ä¸€å¥è¯ã€‚ç¬¬äºŒæ®µçš„ç¬¬äºŒå¥è¯ã€‚ç¬¬äºŒæ®µçš„ç¬¬ä¸‰å¥è¯ã€‚

        ç¬¬ä¸‰æ®µåªæœ‰ä¸€ä¸ªé•¿å¥å­ï¼ŒåŒ…å«æ›´å¤šå†…å®¹æ¥æµ‹è¯•åˆ†å—æ•ˆæœã€‚

        ç¬¬å››æ®µç”¨äºæµ‹è¯•è¾¹ç•Œæƒ…å†µã€‚
        """

    def test_recursive_chunk_basic(self, sample_text: str) -> None:
        """æµ‹è¯•åŸºæœ¬é€’å½’åˆ†å—"""
        config = ChunkingConfig(strategy=ChunkingStrategy.RECURSIVE, chunk_size=200, overlap=0)
        chunks = _recursive_chunk(sample_text, config)
        assert len(chunks) > 0
        assert all(len(c) <= 200 for c in chunks)

    def test_recursive_chunk_preserves_paragraphs(self, sample_text: str) -> None:
        """æµ‹è¯•é€’å½’åˆ†å—ä¿æŒæ®µè½ç»“æ„"""
        config = ChunkingConfig(strategy=ChunkingStrategy.RECURSIVE, chunk_size=500, overlap=0)
        chunks = _recursive_chunk(sample_text, config)
        assert len(chunks) >= 1

    def test_recursive_chunk_empty_text(self) -> None:
        """æµ‹è¯•ç©ºæ–‡æœ¬é€’å½’åˆ†å—"""
        config = ChunkingConfig(strategy=ChunkingStrategy.RECURSIVE)
        chunks = _recursive_chunk("", config)
        assert chunks == []


# ================================
# Cosine Similarity Tests
# ================================


class TestCosineSimilarity:
    """æµ‹è¯•ä½™å¼¦ç›¸ä¼¼åº¦è®¡ç®—"""

    def test_cosine_similarity_identical(self) -> None:
        """æµ‹è¯•ç›¸åŒå‘é‡çš„ç›¸ä¼¼åº¦"""
        a = [1.0, 2.0, 3.0]
        b = [1.0, 2.0, 3.0]
        similarity = _cosine_similarity(a, b)
        assert similarity == pytest.approx(1.0)

    def test_cosine_similarity_orthogonal(self) -> None:
        """æµ‹è¯•æ­£äº¤å‘é‡çš„ç›¸ä¼¼åº¦"""
        a = [1.0, 0.0, 0.0]
        b = [0.0, 1.0, 0.0]
        similarity = _cosine_similarity(a, b)
        assert similarity == pytest.approx(0.0)

    def test_cosine_similarity_opposite(self) -> None:
        """æµ‹è¯•ç›¸åå‘é‡çš„ç›¸ä¼¼åº¦"""
        a = [1.0, 1.0, 1.0]
        b = [-1.0, -1.0, -1.0]
        similarity = _cosine_similarity(a, b)
        assert similarity == pytest.approx(-1.0)

    def test_cosine_similarity_empty_vectors(self) -> None:
        """æµ‹è¯•ç©ºå‘é‡"""
        similarity = _cosine_similarity([], [])
        assert similarity == 0.0

    def test_cosine_similarity_different_lengths(self) -> None:
        """æµ‹è¯•ä¸åŒé•¿åº¦çš„å‘é‡"""
        a = [1.0, 2.0]
        b = [1.0, 2.0, 3.0]
        similarity = _cosine_similarity(a, b)
        assert similarity == 0.0


# ================================
# Semantic Chunking Tests
# ================================


class TestSemanticChunking:
    """æµ‹è¯•è¯­ä¹‰åˆ†å—"""

    @pytest.mark.asyncio
    async def test_semantic_chunk_basic(self) -> None:
        """æµ‹è¯•åŸºæœ¬è¯­ä¹‰åˆ†å—"""
        text = "ç¬¬ä¸€å¥ã€‚ç¬¬äºŒå¥ã€‚ç¬¬ä¸‰å¥ã€‚ç¬¬å››å¥ã€‚"
        config = ChunkingConfig(
            strategy=ChunkingStrategy.SEMANTIC,
            chunk_size=100,
            semantic_threshold=0.85,
        )

        # Mock embedding function
        async def mock_embedding(text: str) -> list[float]:
            base = [0.1] * 1536
            base[0] = len(text) / 100.0
            return base

        chunks = await semantic_chunk_async(text, config, mock_embedding)
        assert len(chunks) > 0

    @pytest.mark.asyncio
    async def test_semantic_chunk_empty_text(self) -> None:
        """æµ‹è¯•ç©ºæ–‡æœ¬è¯­ä¹‰åˆ†å—"""
        config = ChunkingConfig(strategy=ChunkingStrategy.SEMANTIC)

        async def mock_embedding(text: str) -> list[float]:
            return [0.1] * 1536

        chunks = await semantic_chunk_async("", config, mock_embedding)
        assert chunks == []

    @pytest.mark.asyncio
    async def test_semantic_chunk_single_sentence(self) -> None:
        """æµ‹è¯•å•å¥å­æ–‡æœ¬"""
        text = "è¿™æ˜¯å”¯ä¸€çš„ä¸€å¥è¯ã€‚"
        config = ChunkingConfig(strategy=ChunkingStrategy.SEMANTIC)

        async def mock_embedding(text: str) -> list[float]:
            return [0.1] * 1536

        chunks = await semantic_chunk_async(text, config, mock_embedding)
        assert len(chunks) == 1

    @pytest.mark.asyncio
    async def test_semantic_chunk_fallback_on_embedding_failure(self) -> None:
        """æµ‹è¯•åµŒå…¥å¤±è´¥æ—¶å›é€€åˆ°é€’å½’åˆ†å—"""
        text = "ç¬¬ä¸€å¥ã€‚ç¬¬äºŒå¥ã€‚ç¬¬ä¸‰å¥ã€‚"
        config = ChunkingConfig(strategy=ChunkingStrategy.SEMANTIC, chunk_size=200)

        async def failing_embedding(text: str) -> list[float]:
            raise RuntimeError("Embedding failed")

        chunks = await semantic_chunk_async(text, config, failing_embedding)
        # åº”è¯¥å›é€€åˆ°é€’å½’åˆ†å—
        assert len(chunks) > 0


# ================================
# ChunkingStrategy Tests
# ================================


class TestChunkingStrategy:
    """æµ‹è¯• ChunkingStrategy æšä¸¾"""

    def test_strategy_enum_values(self) -> None:
        """æµ‹è¯•ç­–ç•¥æšä¸¾å€¼"""
        assert ChunkingStrategy.FIXED.value == "fixed"
        assert ChunkingStrategy.RECURSIVE.value == "recursive"
        assert ChunkingStrategy.SEMANTIC.value == "semantic"

    def test_config_with_fixed_strategy(self) -> None:
        """æµ‹è¯• FIXED ç­–ç•¥é…ç½®"""
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED, chunk_size=100, overlap=0)
        text = "a" * 200
        chunks = chunk_text(text, config)
        assert len(chunks) == 2

    def test_config_with_recursive_strategy(self) -> None:
        """æµ‹è¯• RECURSIVE ç­–ç•¥é…ç½®"""
        config = ChunkingConfig(strategy=ChunkingStrategy.RECURSIVE, chunk_size=100, overlap=0)
        text = "a" * 200
        chunks = chunk_text(text, config)
        assert len(chunks) > 0

    def test_config_strategy_from_string(self) -> None:
        """æµ‹è¯•ä»å­—ç¬¦ä¸²åˆ›å»ºç­–ç•¥"""
        config = ChunkingConfig(strategy="semantic")
        assert config.strategy == ChunkingStrategy.SEMANTIC

    def test_config_strategy_invalid_string(self) -> None:
        """æµ‹è¯•æ— æ•ˆç­–ç•¥å­—ç¬¦ä¸²"""
        with pytest.raises(ValidationError, match="strategy must be one of"):
            ChunkingConfig(strategy="invalid")


# ================================
# ChunkingConfig Extended Validation Tests
# ================================


class TestChunkingConfigExtended:
    """æµ‹è¯•æ‰©å±•çš„ ChunkingConfig é…ç½®éªŒè¯"""

    def test_config_defaults(self) -> None:
        """æµ‹è¯•é»˜è®¤é…ç½®"""
        config = ChunkingConfig()
        assert config.strategy == ChunkingStrategy.RECURSIVE
        assert config.semantic_threshold == 0.85
        assert config.min_chunk_size == 50
        assert config.max_chunk_size == 2000

    def test_config_custom_semantic_threshold(self) -> None:
        """æµ‹è¯•è‡ªå®šä¹‰è¯­ä¹‰é˜ˆå€¼"""
        config = ChunkingConfig(semantic_threshold=0.9)
        assert config.semantic_threshold == 0.9

    def test_config_validation_semantic_threshold_bounds(self) -> None:
        """æµ‹è¯• semantic_threshold éªŒè¯"""
        with pytest.raises(ValidationError, match="semantic_threshold must be between 0 and 1"):
            ChunkingConfig(semantic_threshold=1.5)

    def test_config_validation_min_chunk_size(self) -> None:
        """æµ‹è¯• min_chunk_size éªŒè¯"""
        with pytest.raises(ValidationError, match="min_chunk_size must be at least 1"):
            ChunkingConfig(min_chunk_size=0)

    def test_config_validation_max_chunk_size(self) -> None:
        """æµ‹è¯• max_chunk_size éªŒè¯"""
        with pytest.raises(ValidationError, match="max_chunk_size must be at least 100"):
            ChunkingConfig(max_chunk_size=50)


# ================================
# Word Boundary Protection Tests
# ================================


class TestWordBoundaryProtection:
    """æµ‹è¯•è‹±æ–‡å•è¯å®Œæ•´æ€§ä¿æŠ¤"""

    def test_find_word_boundary_left(self) -> None:
        """æµ‹è¯•å‘å·¦æŸ¥æ‰¾å•è¯è¾¹ç•Œ"""
        from negentropy.knowledge.chunking import _find_word_boundary

        text = "hello world test"
        # ä½ç½® 7 æ˜¯ 'o'ï¼ˆworld çš„ç¬¬ä¸€ä¸ª oï¼‰
        result = _find_word_boundary(text, 7, "left", 10)
        assert result == 6  # "world" çš„èµ·å§‹ä½ç½®

    def test_find_word_boundary_right(self) -> None:
        """æµ‹è¯•å‘å³æŸ¥æ‰¾å•è¯è¾¹ç•Œ"""
        from negentropy.knowledge.chunking import _find_word_boundary

        text = "hello world test"
        # ä½ç½® 7 æ˜¯ 'o'ï¼ˆworld çš„ç¬¬ä¸€ä¸ª oï¼‰
        result = _find_word_boundary(text, 7, "right", 10)
        assert result == 11  # "world" åçš„ç©ºæ ¼ä½ç½®

    def test_find_word_boundary_at_space(self) -> None:
        """æµ‹è¯•å½“å‰ä½ç½®æ˜¯ç©ºæ ¼çš„æƒ…å†µ"""
        from negentropy.knowledge.chunking import _find_word_boundary

        text = "hello world"
        result = _find_word_boundary(text, 5, "left", 10)  # ä½ç½® 5 æ˜¯ç©ºæ ¼
        assert result == 5

    def test_find_word_boundary_chinese_text(self) -> None:
        """æµ‹è¯•ä¸­æ–‡æ–‡æœ¬ä¸è°ƒæ•´è¾¹ç•Œ"""
        from negentropy.knowledge.chunking import _find_word_boundary

        text = "è¿™æ˜¯ä¸­æ–‡æµ‹è¯•æ–‡æœ¬"
        result = _find_word_boundary(text, 3, "left", 10)
        assert result == 3  # ä¸­æ–‡ä¸è°ƒæ•´

    def test_fixed_chunk_preserves_words(self) -> None:
        """æµ‹è¯• Fixed åˆ†å—ä¿æŠ¤å•è¯å®Œæ•´æ€§"""
        text = "The quick brown fox jumps over the lazy dog multiple times"
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED, chunk_size=20, overlap=0)
        chunks = chunk_text(text, config)

        # æ£€æŸ¥æ²¡æœ‰å•è¯è¢«åˆ‡æ–­
        for chunk in chunks:
            words = chunk.split()
            for word in words:
                # æ¯ä¸ªå•è¯åº”è¯¥æ˜¯å®Œæ•´çš„ï¼ˆå‡ºç°åœ¨åŸæ–‡ä¸­ï¼‰
                assert word in text, f"Word '{word}' was cut in chunk '{chunk}'"

    def test_fixed_chunk_with_overlap_preserves_words(self) -> None:
        """æµ‹è¯• Fixed åˆ†å—å¸¦ Overlap ä¿æŠ¤å•è¯å®Œæ•´æ€§"""
        text = "The quick brown fox jumps over the lazy dog"
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED, chunk_size=25, overlap=10)
        chunks = chunk_text(text, config)

        # æ£€æŸ¥æ¯ä¸ª chunk ä¸­çš„è‹±æ–‡å•è¯éƒ½æ˜¯å®Œæ•´çš„
        import re

        for chunk in chunks:
            # æå–è‹±æ–‡å•è¯
            words = re.findall(r"[a-zA-Z]+", chunk)
            for word in words:
                assert word in text, f"Word '{word}' was cut in chunk '{chunk}'"

    def test_recursive_chunk_overlap_preserves_words(self) -> None:
        """æµ‹è¯• Recursive åˆ†å— Overlap ä¿æŠ¤å•è¯å®Œæ•´æ€§"""
        text = """
        This is a long paragraph that contains many English words.
        We want to ensure that the overlap mechanism does not cut words in half.
        The quick brown fox jumps over the lazy dog.
        """
        config = ChunkingConfig(strategy=ChunkingStrategy.RECURSIVE, chunk_size=50, overlap=20)
        chunks = chunk_text(text, config)

        # æ£€æŸ¥ overlap éƒ¨åˆ†çš„å•è¯å®Œæ•´æ€§
        import re

        for i, chunk in enumerate(chunks):
            words = re.findall(r"[a-zA-Z]+", chunk)
            for word in words:
                assert word in text, f"Word '{word}' was cut in chunk {i}: '{chunk}'"

    def test_mixed_chinese_english_text(self) -> None:
        """æµ‹è¯•ä¸­è‹±æ–‡æ··åˆæ–‡æœ¬"""
        text = "è¿™æ˜¯ä¸­æ–‡This is Englishæ›´å¤šä¸­æ–‡More English hereç»“æŸ"
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED, chunk_size=15, overlap=0)
        chunks = chunk_text(text, config)

        # è‹±æ–‡å•è¯åº”è¯¥ä¿æŒå®Œæ•´
        import re

        for chunk in chunks:
            english_words = re.findall(r"[a-zA-Z]+", chunk)
            for word in english_words:
                assert word in ["This", "is", "English", "More", "here"], (
                    f"Unexpected partial word: '{word}'"
                )

    def test_very_long_word_handling(self) -> None:
        """æµ‹è¯•è¶…é•¿å•è¯å¤„ç†"""
        # åˆ›å»ºä¸€ä¸ªè¶…é•¿å•è¯
        long_word = "supercalifragilisticexpialidocious"
        text = f"The word {long_word} is very long"
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED, chunk_size=20, overlap=0)
        chunks = chunk_text(text, config)

        # è¶…é•¿å•è¯å¯èƒ½éœ€è¦è¢«ä¿ç•™æˆ–ç‰¹æ®Šå¤„ç†
        # è¿™é‡ŒéªŒè¯åˆ†å—ä¸ä¼šå´©æºƒ
        assert len(chunks) > 0

    def test_continuous_text_without_spaces(self) -> None:
        """æµ‹è¯•æ— ç©ºæ ¼çš„è¿ç»­æ–‡æœ¬"""
        text = "abcdefghij" * 10  # 100 ä¸ªå­—ç¬¦ï¼Œæ— ç©ºæ ¼
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED, chunk_size=20, overlap=0)
        chunks = chunk_text(text, config)

        # æ— ç©ºæ ¼æ—¶ï¼Œåº”è¯¥æŒ‰å­—ç¬¦åˆ‡åˆ†
        assert len(chunks) > 0
        total_len = sum(len(c) for c in chunks)
        assert total_len == len(text)

    def test_get_word_safe_overlap(self) -> None:
        """æµ‹è¯•è·å–å•è¯å®‰å…¨çš„é‡å æ–‡æœ¬"""
        from negentropy.knowledge.chunking import _get_word_safe_overlap

        prev_chunk = "This is the previous chunk with words"
        overlap_size = 15

        overlap = _get_word_safe_overlap(prev_chunk, overlap_size)

        # é‡å éƒ¨åˆ†åº”è¯¥æ˜¯å®Œæ•´çš„å•è¯
        assert overlap.strip() in prev_chunk
        # æ£€æŸ¥å¼€å¤´çš„å•è¯æ˜¯å¦å®Œæ•´
        first_word = overlap.strip().split()[0] if overlap.strip() else ""
        if first_word:
            assert first_word in prev_chunk


class TestWordBoundaryEdgeCases:
    """å•è¯è¾¹ç•Œè¾¹ç•Œæƒ…å†µæµ‹è¯•"""

    def test_empty_text(self) -> None:
        """æµ‹è¯•ç©ºæ–‡æœ¬"""
        from negentropy.knowledge.chunking import _find_word_boundary

        assert _find_word_boundary("", 0, "left", 10) == 0
        assert _find_word_boundary("", 0, "right", 10) == 0

    def test_single_character(self) -> None:
        """æµ‹è¯•å•å­—ç¬¦æ–‡æœ¬"""
        from negentropy.knowledge.chunking import _find_word_boundary

        assert _find_word_boundary("a", 0, "left", 10) == 0
        assert _find_word_boundary("a", 0, "right", 10) == 0

    def test_position_at_text_start(self) -> None:
        """æµ‹è¯•ä½ç½®åœ¨æ–‡æœ¬å¼€å¤´"""
        from negentropy.knowledge.chunking import _find_word_boundary

        text = "hello world"
        assert _find_word_boundary(text, 0, "left", 10) == 0

    def test_position_at_text_end(self) -> None:
        """æµ‹è¯•ä½ç½®åœ¨æ–‡æœ¬æœ«å°¾"""
        from negentropy.knowledge.chunking import _find_word_boundary

        text = "hello world"
        assert _find_word_boundary(text, len(text) - 1, "right", 10) == len(text) - 1

    def test_numbers_and_punctuation(self) -> None:
        """æµ‹è¯•æ•°å­—å’Œæ ‡ç‚¹ç¬¦å·"""
        from negentropy.knowledge.chunking import _find_word_boundary

        text = "hello123 world test"
        # æ•°å­—å’Œæ ‡ç‚¹ä¸è¢«è§†ä¸ºè‹±æ–‡å•è¯çš„ä¸€éƒ¨åˆ†
        result = _find_word_boundary(text, 5, "right", 10)
        # '123' ä¸æ˜¯è‹±æ–‡å­—æ¯ï¼Œåº”è¯¥åœ¨æ­¤å¤„åœæ­¢
        assert result <= 8  # æœ€å¤šåˆ° 123 çš„ä½ç½®

    def test_multiple_spaces(self) -> None:
        """æµ‹è¯•å¤šä¸ªè¿ç»­ç©ºæ ¼"""
        text = "hello   world"
        config = ChunkingConfig(strategy=ChunkingStrategy.FIXED, chunk_size=10, overlap=0)
        chunks = chunk_text(text, config)
        # åº”è¯¥æ­£å¸¸å¤„ç†å¤šä¸ªç©ºæ ¼çš„æƒ…å†µ
        assert len(chunks) > 0
